Нейросети для детей

Всем привет! Несмотря на некоторое уныние от самоизоляции, сегодня я хочу рассказать о том, как устроены нейросети, но так просто, что понять могут даже дети, которые освоили только самые основы питона.


<h3> Что такое вообще нейронный сети и искуственный интеллект?</h3>
Существует два вида искуственного интеллекта - сильный и слабый.  Теория сильного искуственного интеллекта предполагает, что компьютеры смогут обрести способность мыслить и осознавать себя как отдельную личность( ну примерно как Detroit Become Human). Теория слабого искуственного интеллекта предполагает, что такой интеллект нельзя сконструировать. Пока что наука особо не способна создать такой инетелкт, но не об этом сейчас. 
<h3>А что такой нейронные сети </h3>
Нейронные сети в Computer Science представляют собой математические модели работы реальных нейронных сетей(да, в физиологии ЦНС их называют также). Математическую модель просто перевести в программу(и из-за этого в программировании нейронных сетей так широко используется Python, столь удобный для программирования решения математических задач. На самом деле нейронные сети можно написать на практически любом языке программирования, в котором поддерживается какая-никакая математика. Даже на Scratch, который изначально создан для обучения основам программирования дошкольников <a href="https://scratch.mit.edu/projects/26859854/"> этом</a> ).
<h3> Основные понятия нейросетей </h3>
Существует множество алгоритмов работы нейросетей(и сейчас математическая сторона этого вопроса активно разрабатывается). Классическим решением для новичков является метод обратного распостранения ошибок(backpropagation)  - метод вычисления градиента, который используется для обновления весов многослойного перцептрона.
Стоп? Что такое вообще веса?
Пришла пора немного ознакомится с основными понятиями и как работает примитивнейшая нейронная сеть.
Та программа, которую мы собираемся написать называется нейронной сетью с огромной натяжкой.
Прежде чем перейти к ее описанию, давайте обсудим, чем вообще занимаются нейронные сети.

<h3>  Чем вообще занимаются нейросети, если все упростить </h3>
Если немного упростить концепцию нейронных сетей, то нейросети, которые обучаются по принципу обучения с учителем, после обучения по приципу "стимул - рекция", с указанием правильных ответов, она может работать с <i> незнакомыми </i> данными. Иными словами, если вы предложили нейросети на вход некий набор слов(например, набор отзывов на кинопоиске, положительных и отрицательных, в любом формате, хоть txt, хоть json, здесь вопрос стоит только в заргрузке этих данных). Для успешного создания нейросети вам потребуются два набора данных: тестовой набор, с помощью которого можно будет оценить эффективность работы созданной нейросети, и обучающий набор, в котором данные размечены на положительные/отрицательные(проблема классификации данных). После обучения нейросети(момент, который может занять довольно продолжительное время и ресурсы железа, в зависимости от размерности данных, их обработки, и что чаще всего самое главное, применяемых алгоритмов), она сможет <i> пытаться</i> предугададывать с некоторой точностью, положительный или отрицательный отзыв. Но нейросети (как впрочем и реальный человек, занимающийся), имеют некоторый процент ошибки. Задача оптимизации - сделать его минимальным, но вопрос оценки качества нейросетей тоже стоит особняком. К примеру, вам дают фотографию хот-дога, и здесь вы точно говорите, что это хот-дог. Но что если фотография будет смазана? Черно-белая? Снята в плохой видимости? Здесь вы сможете уже утверждать только с некоторой долей вероятности, даже если приготовили или съели немало хот-догов в своей жизни.

<h3> Начинаем прграммировать нашу игрушечную нейросеть</h3>
Окей, тогда начинаем программировать нашуй игрушечную нейросеть. В ней не будет тестовых и тренировочных данных, наша игрушечная нейросеть будет пытаться найти <i> коэфицент</i> между любыми данными.
Стоп. А какой в этом смысл? Это же находится одним простым математическим выражением.
Вне сомнения. Однако сейчас я взял это выражение, чтобы показать процесс обучения нейросети. Допустим, перед нами стоит задача выяснить, какой коэфицент перевода между дюймами и сантиметрами. Сколько дюйма занимает один сантиметр? Для человека, который знает математику хотя бы пятого класса( а то и раньше), не составляет труда выяснить  с помощью 1/2.54 что один сантиметр составляет 0.0393( я округлил).
Но сейчас мы на время забудем об этом, и представим, что нам нужно создать простой алгоритм, коорый будет универсально вычислять этот параметр. И дело в том, что нейросети не являются некоторыми константами значений с готовыми значениями коэфицентов, иначе бы в них не было "живого" обучения. 
Итого, мы в положении ребенка, который только сел перед набором кубиков, и собирается взять их впервые в свои руки и соорудить первую в своей жизни башенку. Он только примерно знает, как работает физика предметов, так же как и мы знаем, что какой-то определенный коэфицент обучения существует. Так что сделает ребенок? Он возьмет и наугад поставит какой-то кубик. Точно также мы мы можем только наугад преположить, какой у нас будет коэфицент (и реальные взрослые нейросети тоже так делают, только руководствуясь некоторой генерацией в нормальном распределении). Просто наугад предположим что коэфицент связи дюймов и сантиметров(давайте начнем его называть <b>вес</b>, как во взрослых нейросетях) будет равен, к примеру, 0.4. Тогда у нас получится сложнейшее математическое выражение:
<source>
2.54 * 0.4 = 1.016
</source>
Здорово, мы почти угадали, и у нас есть некоторый результат.  Но он неверный. и что нормально для процесса обучения, у нас есть некоторая ошибка. Как нервная система с обратной связью, нам нужно как-то срегировать на ошибку. Но сначала нужно понять ее размер. В нейросетях обучения с учителем сначала данные прогоняют на размеченных данных, и только потом уже отправляют в классификацию на похожих, но неразмеченных. Так же и мы знаем, какой у нас должен получится правильный результат, и я смогу подсчитать ошибку:
<source>
t_target = 1.0
t_now = 1.016
e = t_target - t_now
//получаем значение е, равное сейчас 0.016
</source>	
Теперь мы знаем, насколько ошиблись. Но что нам делать? Естественно, наша игрушеная нейросеть должна считать данные как можно с наименьшим коэфицентом ошибки. И в этом проявляется ещё одна подводная особенность нейросетей - чаще всего они имеют некоторый коэфицент потери при обучении, минимазацией ошибки занимается часть Data Science, под названием <a href="https://ru.wikipedia.org/wiki/%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_(%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)">оптимизация</a>. 
Но сейчас не об этом. Вне сомнения, нам нужно начать изменять наш коэфицент связи на какой-то шаг, на на какой? Очевидно, что надо не слишком большой, а то наш коэфицент связи получится неточным, и не слишком маленький, иначе нам придется довольно долго обучать нашу нейросеть. Здесь особо нет правильного решения, чаще всего эти параметры и в реальной нейросети подбираются скорее интуитивно, чем на основании какой то формулы или алгоритма (хотя такое тоже возможно).  Сейчас мы можем наугад выбрать значение нашего шага ( на языка нейростей наш шаг называется learning_rate), к примеру, достаточно оптимально будет работать работать значение 0.05. Кроме этого, нужно договориться о том, сколько раз у нас будет происходить отступ на <b>learning rate</b>. Количество этих отступов мы назовем эпохи, как во взрослых нейросетях. Теперь, вооружившись всеми этими знаниями, мы можем попробовать написать небольшую программу на Python, которая будет выполнять нашу программу "игрушечной" нейросети.
<source lang="python"> 
import random

# возьмем встроенную в Python библиотеку random, что мы могли задавать случаный вес нашей нейросети

inches = 40  # мы знаем что 40 дюймов равняется примерно 101, 6 сантиметрам
centimetre = 101.6


# подбор коэфицент связи. Уже по взрослому называю его весом


# создаем функцию, которая занимается подбором и принимает на вход эпохи, learning rate и  точность

def kid_neuro(epoch, lr, accur):
    W_coef = random.uniform(0, 1)  # получаем наш случайный вес связи
    print("Наш первоначальный случайный вес равен: ", W_coef)
    for i in range(epoch):  # воспользуемся циклом для прокрутки
        Error = centimetre - (inches * W_coef)
        print("Наша ошибка составляет", Error)  # будем печатать ошибку для нашей визуализации
        if Error > 0:
            W_coef += lr  # если ошибка слишком большая, мы начинаем прибавлять коэфицент

        if Error < 0:
            W_coef -= lr  # если ошибка отрицательная, тогда начинаем уменьшать коэфицент

        if Error < accur:
            print("Наш итоговый результат", W_coef)
            return  # эффектно вычисляем, сколько же сайнтиметров в одном дюйме


epoch = int(input("epoch: "))  # эпохи это у нас количество "прогонов"
lr = float(input("enter learning rate: "))  # наш шаг обучения
accur = float(input(
    "enter accurancy:  "))  # нам нужно уточнить, на какую точность мы согласны, потому что идеальной у нас скорее всего не получится

kid_neuro(epoch, lr, accur)
</source>
Я оставляю читателя самостоятельно попробовать позапускать эту детскую нейронную сеть с различными параметрами. Достаточно надежно получается на epoch = 100, learning rate = 0.01, accur = 0.1(правда неточно).
Несмотря на кажующуюся бесполезность этой программмы и этого, мы разобрали с вами работу и основные понятия нейронных сетей, которые используются и в построении реальных больших нейронных сетей, к примеру алгоритмы обратного распостранения ошибки(backprogation). Вкратце, эти основные понятия:
<ul>
	<li> <b>W</b> - вес. Вес обычно показывает связь узла нейронной сети с каким-то понятием, если нейросеть настроена на классификацию. У нас был только один вес - коэфицент взаимосвязи между дюймами и сантиметрами, но обновляли мы его примерно также, как в реальной неройсети </li>
	<li>
		<b>lr</b> - learning rate, или скорость обучения. Показывает с каким шагомы мы будем  <i>обновлять</i> нашу связь при каждом прогоне
	</li>
	<li> <b>epoch</b>  Эпохи, или сколько прогонов у нас будет для достижения максимально точного результата </li>
</ul>

В качестве практики вы можете попробовать написать свою детскую нейросеть, которая будет переводить, к примеру, километры в мили. И вооружившись полученными в данной статье знаниями, вы сможете без проблем прийти например <a href="https://playground.tensorflow.org/">сюда</a> , и уже попробовать позапускать нейросеть более осмысленно.

Несколько полезные ссылок, на которые вы можете перейти, если желаете продолжить обучение нейросетям:
<a href="https://habr.com/ru/post/312450/">Хорошая серия статей про нейроести на русском на Хабре</a>
<a href="https://www.allaboutcircuits.com/technical-articles/how-to-perform-classification-using-a-neural-network-a-simple-perceptron-example/"> Перцептроны в одиночку используются в современных нейросетях не очень широко. Но начать свой путь именно с них хорошая идея</a>
<a href="https://medium.com/@mjbhobe/mnist-digits-classification-with-keras-ed6c2374bd0e"> Если вы собираетесь разиваться в нейросетях, написать что-то на Mnist - хорошая идея</a>














































